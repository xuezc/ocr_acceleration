# MEAL: Multi-Model Ensemble via Adversarial Learning阅读笔记

## 1.论文内容

&emsp;&emsp;通常，性能最好的深层神经模型是多个基层网络的集合。不幸的是，存储这些网络所需的空间以及在测试时执行这些网络所需的时间，使得很难在测试集很大的应用程序（例如ImageNet）中使用它们。本文提出了一种将大型复杂训练集压缩成单一网络的方法，将来自不同训练深度神经网络（DNNs）的知识提取出来，并转化为单一DNN。为了从不同的训练（教师）模型中提取不同的知识，文章提出了使用基于对抗的学习策略，定义一个分块的训练损失来指导和优化预先定义的学生网络，以恢复教师模型中的知识，并促进鉴别器网络区分同时出现的教师和学生特征。文章提出的集成方法（MEAT）具有三个重要的优点：（1）用判别器学习抽象知识的学生网络比原模型得到了更好的优化；（2）通过一次前向传递实现快速推理，学生网络可以从具有任意结构的教师模型中学习到提炼出来的知识。在CIFAR-10/100、SVHN和ImageNet数据集上的大量实验证明了提出的MEAL方法的有效性。提出的方法的网络结构图如下图所示

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image1.png)

&emsp;&emsp;在网络结构中，包括了学生网络、老师网络、校准层（alignment layers）、相似度损失层和判别器。学生网络和老师网络产生中间输出进行校正，校正层是一个自适应池化的过程，将相同或不同长度的特征向量作为输入并产生固定长度的新特征。学生网络与几个判别器进行对抗训练，使其产生与老师网络相似的输出。

&emsp;&emsp;首先，在给定的数据集上使用交叉熵损失函数预训练老师网络，label是one-hot类型的图片集标注；学生网络在相同的数据集上进行训练，使用的label是老师网络产生的，即soft label。当学生网络进行训练时，老师网络的参数固定，即不进行学习，同时最小化学生网络输出和soft label的相似度距离

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image2.png)

&emsp;&emsp;自适应池化的目的是将教师网络和学生网络的中间输出对齐。这种层类似于普通的池层，如平均池化或最大池化，但可以生成具有不同输入大小的预定义输出长度。由于这一特殊性，我们可以使用不同的教师网络，将输出集中到相同长度的学生输出。在降低特征映射分辨率的同时，池化层也可以实现空间不变性。因此，中间输出的损失函数是：

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image3.png)

&emsp;&emsp;自适应池化的过程见下图

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image4.png)

&emsp;&emsp;由于采用了多个中间输出层，所以最终的相似度损失为

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image5.png)

&emsp;&emsp;判别器主要判断输入的x是老师还是学生产生的，最大化以下公式的值，同时学生网络为了尽可能产生于老师相似的输出，所以追求最小化该公式的值

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image6.png)

&emsp;&emsp;则多阶段判别器的公式为

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image7.png)

&emsp;&emsp;判别器的结构如下图所示

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image8.png)

&emsp;&emsp;因此，最终网络的损失为

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image9.png)

&emsp;&emsp;项目的github地址为https://github.com/AaronHeee/MEAL，在代码中已有详细的注释。

## 2.实验

&emsp;&emsp;在实验中，同时以vgg19,densenet,dpn92,resnet18和preactresnet18为教师网络，以densenet为学生网络，在cifar10数据集上，使用MEAL法进行蒸馏训练，目前训练了85个epochs，准确率为89.82%，具体教师网络的情况为

![paper](https://github.com/xuezc/ocr_acceleration/blob/master/images/image10.PNG)